{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ### Q1: Install and load the latest versions of TensorFlow and Keras. Print their versions.\n",
    "\n",
    "# ```python\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "\n",
    "# print(\"TensorFlow Version:\", tf.__version__)\n",
    "# print(\"Keras Version:\", keras.__version__)\n",
    "# ```\n",
    "\n",
    "# ### Q2: Load the Wine Quality dataset and explore its dimensions.\n",
    "\n",
    "# We will use the Wine Quality dataset from the UCI Machine Learning Repository. First, download the dataset and save it as `winequality-red.csv`.\n",
    "\n",
    "# ```python\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the dataset\n",
    "# data = pd.read_csv('winequality-red.csv', delimiter=';')\n",
    "\n",
    "# # Explore its dimensions\n",
    "# print(\"Dataset Dimensions:\", data.shape)\n",
    "# ```\n",
    "\n",
    "# ### Q3: Check for null values, identify categorical variables, and encode them.\n",
    "\n",
    "# ```python\n",
    "# # Check for null values\n",
    "# print(\"Null Values:\\n\", data.isnull().sum())\n",
    "\n",
    "# # Identify categorical variables\n",
    "# categorical_vars = data.select_dtypes(include=['object']).columns\n",
    "# print(\"Categorical Variables:\", categorical_vars)\n",
    "\n",
    "# # Encode categorical variables (if any)\n",
    "# for var in categorical_vars:\n",
    "#     data[var] = pd.factorize(data[var])[0]\n",
    "# ```\n",
    "\n",
    "# ### Q4: Separate the features and target variables from the dataframe.\n",
    "\n",
    "# ```python\n",
    "# # Separate features and target\n",
    "# X = data.drop('quality', axis=1)\n",
    "# y = data['quality']\n",
    "\n",
    "# # For binary classification, let's create a binary target\n",
    "# y = (y >= 7).astype(int)\n",
    "# ```\n",
    "\n",
    "# ### Q5: Perform a train-test split and divide the data into training, validation, and test datasets.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Perform train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Further split training data into training and validation datasets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "# ```\n",
    "\n",
    "# ### Q6: Perform scaling on the dataset.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Scale the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# ```\n",
    "\n",
    "# ### Q7: Create at least 2 hidden layers and an output layer for the binary categorical variables.\n",
    "\n",
    "# ### Q8: Create a Sequential model and add all the layers to it.\n",
    "\n",
    "# ```python\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# # Create a Sequential model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add layers to the model\n",
    "# model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "# ```\n",
    "\n",
    "# ### Q9: Implement a TensorBoard callback to visualize and monitor the model's training process.\n",
    "\n",
    "# ```python\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "# import datetime\n",
    "\n",
    "# # Define TensorBoard callback\n",
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# ```\n",
    "\n",
    "# ### Q10: Use Early Stopping to prevent overfitting by monitoring a chosen metric and stopping the training if no improvement is observed.\n",
    "\n",
    "# ```python\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Define Early Stopping callback\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# ```\n",
    "\n",
    "# ### Q11: Implement a ModelCheckpoint callback to save the best model based on a chosen metric during training.\n",
    "\n",
    "# ```python\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Define ModelCheckpoint callback\n",
    "# checkpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "# ```\n",
    "\n",
    "# ### Q12: Print the model summary.\n",
    "\n",
    "# ```python\n",
    "# # Print model summary\n",
    "# model.summary()\n",
    "# ```\n",
    "\n",
    "# ### Q13: Use binary cross-entropy as the loss function, Adam optimizer, and include the metric ['accuracy'].\n",
    "\n",
    "# ### Q14: Compile the model with the specified loss function, optimizer, and metrics.\n",
    "\n",
    "# ```python\n",
    "# # Compile the model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# ```\n",
    "\n",
    "# ### Q15: Fit the model to the data, incorporating the TensorBoard, Early Stopping, and ModelCheckpoint callbacks.\n",
    "\n",
    "# ```python\n",
    "# # Fit the model\n",
    "# history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),\n",
    "#                     callbacks=[tensorboard_callback, early_stopping_callback, checkpoint_callback])\n",
    "# ```\n",
    "\n",
    "# ### Q16: Get the model's parameters.\n",
    "\n",
    "# ```python\n",
    "# # Get model's parameters\n",
    "# model_params = model.get_weights()\n",
    "# ```\n",
    "\n",
    "# ### Q17: Store the model's training history as a Pandas DataFrame.\n",
    "\n",
    "# ```python\n",
    "# # Store training history\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "# ```\n",
    "\n",
    "# ### Q18: Plot the model's training history.\n",
    "\n",
    "# ```python\n",
    "# # Plot training history\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot accuracy\n",
    "# plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot loss\n",
    "# plt.plot(history_df['loss'], label='Training Loss')\n",
    "# plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "# plt.title('Model Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# ### Q19: Evaluate the model's performance using the test data.\n",
    "\n",
    "# ```python\n",
    "# # Evaluate the model\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# print(\"Test Loss:\", test_loss)\n",
    "# print(\"Test Accuracy:\", test_accuracy)\n",
    "# ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
